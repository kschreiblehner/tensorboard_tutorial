{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard - LiveHandsOn\n",
    "\n",
    "In diesem Jupyter-Notebook werden Beispiele zur Nutzung von TensorBoard gezeigt. Insbesondere wird auf die Themen\n",
    "\n",
    "1. Darstellung von Metriken für Trainigs- und Validierungsdaten,\n",
    "2. Anzeige des Modellgraphen und\n",
    "3. Tuning von Hyperparametern\n",
    "\n",
    "eingegangen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der notwendigen Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz\n",
    "\n",
    "Im Folgenden wird der <a href='https://github.com/zalandoresearch/fashion-mnist'>Fashion-MNIST Datensatz</a> verwendet. Dieser besteht aus graustufen Bildern der Größe 28x28 Pixel. Ferner sind alle Bilder in eine von zehn Klassen eingeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dazu kann ein Beispiel-Sample der Daten generiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellung des Modells\n",
    "\n",
    "Das Modell bekommt als Eingabe die Bilder als 28x28 Matrix und gibt eine Wahrscheinlichkeit für die einzelnen Labels (0-9) aus. Das Mapping der Labels ist\n",
    "\n",
    "- 0 -> T-shirt/top, \n",
    "- 1 -> Trouser, \n",
    "- 2 -> Pullover, \n",
    "- 3 -> Dress, \n",
    "- 4 -> Coat,\n",
    "- 5 -> Sandal, \n",
    "- 6 -> Shirt, \n",
    "- 7 -> Sneaker, \n",
    "- 8 -> Bag und\n",
    "- 9 -> Ankle boot.\n",
    "\n",
    "Anschließend wird das Modell kompiliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard-Callback\n",
    "Innerhalb von Keras können Callbacks für Anweisungen zur Laufzeit verwendet werden. Dazu setzt man ein Directory für die Log-Dateien `log_dir`. Der Parameter `write_graph` dient zur Visualisierung des Berechnungsgraphen von dem Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/tf/tensorboard_log/run_' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, write_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging eines Keras-Modells\n",
    "Zum Training des werden zu Vorführzwecken lediglich die ersten 1000 Bilder der Trainingsdaten genutzt. Innerhalb eines Keras-Modells kann über die `fit`-Methode das TensorBoard-Callback über den Parameter `callbacks` beim Training übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_images[:1000],\n",
    "          y=train_labels[:1000],\n",
    "          epochs=50,\n",
    "          validation_data=(test_images, test_labels),\n",
    "          callbacks=[tensorboard_callback],\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging eigener Kenngrößen\n",
    "\n",
    "Zur Darstellung von selbst-erstellten Kenngrößen wird ein von TensorFlow bereitgestellter Writer für Log-Files  verwendet. Dieser wird mittels `tensorflow.summary.create_file_writer(LOGDIR)` erstellt. Mittels `tensorflow.summary.scalars` kann  die Darstellung im TensorBoard unter dem Tab `Scalars` geplottet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/tf/tensorboard_log/run_' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "train_log_dir = os.path.join(log_dir, 'my_scalar')\n",
    "train_log_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "x_i = 0.\n",
    "for (i, x) in zip(np.arange(50), np.random.normal(0, 1, 50)):\n",
    "    with train_log_writer.as_default():\n",
    "        x_i += (x+1)/2\n",
    "        tf.summary.scalar('epoch_loss', x_i, step=i)     \n",
    "        tf.summary.scalar('my_scalar', x_i, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse von Hyperparametern\n",
    "\n",
    "Bei der Bearbeitung einer Aufgabe ist es oft vonnöten, verschiedene Modelle zu vergleichen. Insbesondere ist die Konfiguration eines Netzes ausschlaggebend für die Qualität einer Lösung. Zur Analyse mehrerer Parameterkonfigurationen kann die `HParams`-Funktion von Tensorboard genutzt werden. Solche Parameter können der verwendete Optimierer und derer Lernraten, verschiedene Netzkonfigurationen selbst, etc. sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition der zu testenden Parameter\n",
    "\n",
    "Die zu testenden Parameter können über die TensorBoard-Extension `hparams` definiert werden. Zum Schreiben des Log-Files für HParams wird die Konfiguration über die `hparams_config` an einen TensorFlow-Writer übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([512, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0., 1.))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung des Modells\n",
    "\n",
    "Zur zeitlichen Begrenzung der Laufzeit werden hier lediglich 1000 Samples der Trainingsdaten verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_units, dropout_rate):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_units, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def compile_and_fit(model, hparams, epochs, log_dir):\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_images[:1000],\n",
    "        train_labels[:1000],\n",
    "        epochs=epochs,\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir),\n",
    "                   hp.KerasCallback(log_dir, hparams=hparams)],\n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Modells\n",
    "\n",
    "Zum Test der Hyperparameter werden die Netze für die einzelnen Konfigurationen trainiert. Im Allgemeinen ist es sinnvoll, schon in den ersten Phasen der Bearbeitung einer Aufgabe mit dem Logging der Parameter zu beginnen. Der Vergleich kann somit über frühere Modelle geschehen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in np.random.random_sample(3):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer\n",
    "            }\n",
    "            \n",
    "            print('Running example with\\nunits: {}\\ndropout_rate: {}\\noptimizer: {}'\n",
    "                  .format(units, dropout_rate, optimizer))\n",
    "            \n",
    "            log_dir = '/tf/tensorboard_log/hparam_tuning/run_' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "            \n",
    "            model = create_model(units, dropout_rate)\n",
    "            _ = compile_and_fit(model, hparams, 10, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
